{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funded-forest",
   "metadata": {},
   "source": [
    "# ML-MOGA User Manual\n",
    "\n",
    "Languages: Python(3.7.9), C++ <br />\n",
    "Tools: PyTorch(1.4.0+), Jupyter Notebook(6.2.0) (both can be installed via conda)<br />\n",
    "CAM(cam.lbl.gov): Data processing and training <br />\n",
    "NERSC: MOGA running(both Tr-MOGA & ML-MOGA)\n",
    "\n",
    "If you have any question, contact yupinglu89@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-auction",
   "metadata": {},
   "source": [
    "## Tr-MOGA \n",
    "\n",
    "#### 1. Load modules on NERSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "module purge\n",
    "module load PrgEnv-gnu\n",
    "module load openmpi\n",
    "module load gsl\n",
    "module load pytorch/v1.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-virginia",
   "metadata": {},
   "source": [
    "#### 2. Set up MOGA code\n",
    "\n",
    "Example code(NERSC/nl-run/run_ori/1_moga). <br />\n",
    "Compile the code in ML_package folder and get the executable by typing \"make\".<br />\n",
    "Submit scanjob.s listed below to schedule the job on NERSC. The time limit on NERSC is 48 hrs for regular queue. You can also submit to 30 minutes debug queue for fast execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --qos=regular\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --nodes=64\n",
    "#SBATCH --tasks-per-node=32\n",
    "#SBATCH --constraint=haswell\n",
    "#SBATCH --mail-user=yupinglu89@gmail.com\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --job-name=MOGA\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "echo Working directory is : $SLURM_SUBMIT_DIR\n",
    "\n",
    "echo $SLURM_JOB_NODELIST\n",
    "echo $SLURM_JOBID\n",
    "echo $SLURM_NPROCS\n",
    "\n",
    "# NCPUS=`wc -l $SLURM_NODELIST| awk '{print $1}'`\n",
    "# JobID=`echo ${SLURM_JOBID} | cut -f1 -d.`\n",
    "\n",
    "NCPUS=$SLURM_NPROCS\n",
    "JobID=$SLURM_JOBID\n",
    "\n",
    "mkdir Dir_$JobID\n",
    "cd Dir_$JobID\n",
    "cp ../problem.cpp ./\n",
    "cp ../tracking.in ./\n",
    "cp ../scanjob.s ./\n",
    "cp ../ALSU.cpp ./\n",
    "cp ../ALSU.h ./\n",
    "cp ../input_gen.dat ./\n",
    "\n",
    "echo \"Start parallel job with CPUS\"\n",
    "echo $NCPUS\n",
    "echo \" -----------------------------------------------\"\n",
    "\n",
    "#module purge\n",
    "#module load PrgEnv-gnu\n",
    "#module load openmpi\n",
    "#module load gsl\n",
    "#module load pytorch\n",
    "####### Problem mode (0-DASearch, 1-FreqMap, 2-DiffMomen, 3-AreaMomen) ###########\n",
    "#####  1 for read pop, 2 for read gen\n",
    "##### MOGA random seed 0.5\n",
    "EXEC=\"../nsga2r 0.5 3  2\"\n",
    "\n",
    "mpirun -v -np $NCPUS $EXEC <../tracking.in >$SLURM_SUBMIT_DIR/stdout_$JobID.out 2>$SLURM_SUBMIT_DIR/stderr_$JobID.out\n",
    "\n",
    "mv ../*$JobID.out ../slurm-*.out ../Dir_$JobID/\n",
    "\n",
    "### END of job\n",
    "echo \"Job complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch scanjob.s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-opportunity",
   "metadata": {},
   "source": [
    "#### 3. Retrieve results (gen_*_db.dat files)\n",
    "\n",
    "These files are stored in Dir\\_\\* folder.<br />\n",
    "Delete the first line of each gen\\_\\*\\_db.dat file.\n",
    "\n",
    "     20 outputs,   11 variables,   conViol  rank  crowDist\n",
    "\n",
    "#### 4. Change random seeds\n",
    "\n",
    "We tested the moga code by changing two random seeds.<br />\n",
    "Change MOGA random seed: EXEC=\"../nsga2r 0.1 3  2\" (in scanjob.s)<br />\n",
    "Change lattice error random seed: srand(2021); (in problem.cpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-examination",
   "metadata": {},
   "source": [
    "## Machine Learning Approach\n",
    "\n",
    "+ We first preprocess training data acquired from prior simulations and use this data to obtain two well-trained models using the neural network (NN) depicted below. \n",
    "+ We then use these two NN models to replace DA/MA particle tracking in MOGA while the rest of the MOGA setup remains the same as in the original tracking-based MOGA (Tr-MOGA). \n",
    "+ We evaluate the results.\n",
    "\n",
    "<img src=\"cnn.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "8-layer fully-connected (FC) NN architecture for DA and MA prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-germany",
   "metadata": {},
   "source": [
    "## ML-MOGA \n",
    "\n",
    "\n",
    "\n",
    "#### 1. Training Data\n",
    "\n",
    "We used the first 10 dat files as training data. These data are stored in dat folder on CAM. Below are two python scripts to preprocess the data (include filtering out those not meet the constraints).\n",
    "\n",
    "python pre.da.py<br />\n",
    "python pre.ma.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "MOGA data preprocessing for dynamic aperture\n",
    "pre.da.py\n",
    "'''\n",
    "\n",
    "# load libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# load files\n",
    "path = './dat/'\n",
    "fs = os.listdir(path)\n",
    "data = []\n",
    "\n",
    "# read files\n",
    "for f in fs:\n",
    "    tmp_df = pd.read_csv(path+f, header=None)\n",
    "    data.append(tmp_df)\n",
    "df = pd.concat(data, ignore_index=True, sort =False)\n",
    "\n",
    "# get X and Y\n",
    "data = df.to_numpy()\n",
    "x = data[:, -3]\n",
    "data = data[x == 0]\n",
    "X = data[:,20:31]\n",
    "Y_t = data[:,15:17]\n",
    "Y = np.mean(Y_t, axis=1)\n",
    "\n",
    "# split data into training set and test set\n",
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(X, Y, test_size=0.20, random_state=2020)\n",
    "\n",
    "# data normalization to [0, 1]\n",
    "x_mean = np.mean(x_train_o, axis=0)\n",
    "x_std = np.std(x_train_o, axis=0)\n",
    "print(x_mean)\n",
    "print(x_std)\n",
    "\n",
    "x_train = (x_train_o - x_mean) / x_std\n",
    "x_test = (x_test_o - x_mean) / x_std\n",
    "y_train = y_train_o\n",
    "y_test = y_test_o \n",
    "print(len(y_test))\n",
    "\n",
    "moga = {\n",
    "    \"x_train\": x_train,\n",
    "    \"x_test\": x_test,\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "    \"x_mean\": x_mean,\n",
    "    \"x_std\": x_std,\n",
    "}\n",
    "\n",
    "# save data\n",
    "pickle.dump(moga, open(\"da.1208.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "MOGA data preprocessing for momentum aperture\n",
    "pre.ma.py\n",
    "'''\n",
    "\n",
    "# load libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# load files\n",
    "path = './dat/'\n",
    "fs = os.listdir(path)\n",
    "data = []\n",
    "\n",
    "# read files\n",
    "for f in fs:\n",
    "    tmp_df = pd.read_csv(path+f, header=None)\n",
    "    data.append(tmp_df)\n",
    "df = pd.concat(data, ignore_index=True, sort =False)\n",
    "\n",
    "# get X and Y\n",
    "data = df.to_numpy()\n",
    "x = data[:, -3]\n",
    "data = data[x == 0]\n",
    "X = data[:,20:31]\n",
    "Y = data[:,17]\n",
    "\n",
    "# split data into training set and test set\n",
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(X, Y, test_size=0.20, random_state=2020)\n",
    "\n",
    "# data normalization to [0, 1]\n",
    "x_mean = np.mean(x_train_o, axis=0)\n",
    "x_std = np.std(x_train_o, axis=0)\n",
    "print(x_mean)\n",
    "print(x_std)\n",
    "\n",
    "x_train = (x_train_o - x_mean) / x_std\n",
    "x_test = (x_test_o - x_mean) / x_std\n",
    "y_train = y_train_o\n",
    "y_test = y_test_o \n",
    "print(len(y_test))\n",
    "\n",
    "moga = {\n",
    "    \"x_train\": x_train,\n",
    "    \"x_test\": x_test,\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test,\n",
    "    \"x_mean\": x_mean,\n",
    "    \"x_std\": x_std,\n",
    "}\n",
    "\n",
    "# save data\n",
    "pickle.dump(moga, open(\"ma.1208.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-disabled",
   "metadata": {},
   "source": [
    "#### 2. Model Training\n",
    "\n",
    "The two model scripts will load ma.1208.pkl and da.1208.pkl and start the model training.\n",
    "\n",
    "nohup python ma.py > ma.out 2> ma.err < /dev/null & <br />\n",
    "nohup python da.py > da.out 2> da.err < /dev/null &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# ma.py\n",
    "# load libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# definition of a simple fc model\n",
    "class MOGANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MOGANet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(11, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MOGADataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "# define train and test functions\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    return train_loss\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # compute output\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    test_loss /= len(test_loader)\n",
    "    return test_loss\n",
    "\n",
    "# Use CUDA\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(2020) \n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed_all(2020)\n",
    "\n",
    "# load files\n",
    "moga = pickle.load(open(\"ma.1208.pkl\", \"rb\"))\n",
    "x_train, x_test = moga[\"x_train\"], moga[\"x_test\"]\n",
    "y_train, y_test = moga[\"y_train\"], moga[\"y_test\"]\n",
    "x_mean, x_std = moga[\"x_mean\"], moga[\"x_std\"]\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test.reshape(-1,1)).float()\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 128,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 4}\n",
    "\n",
    "# dataloader\n",
    "train_data = MOGADataset(x_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_data, **params)\n",
    "\n",
    "test_data = MOGADataset(x_test, y_test)\n",
    "test_loader = DataLoader(dataset=test_data, **params)\n",
    "\n",
    "model = MOGANet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8)\n",
    "\n",
    "# Training here\n",
    "for t in range(500):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion) \n",
    "    test_loss = test(model, device, test_loader, criterion)\n",
    "    if t%10 == 0:\n",
    "        print(t, train_loss, test_loss)\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "# save trained model\n",
    "torch.save(model.state_dict(), 'ma.1208.pth')\n",
    "#model.load_state_dict(torch.load(\"ma.1208.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# da.py \n",
    "# load libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# definition of a simple fc model\n",
    "class MOGANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MOGANet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(11, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MOGADataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "# define train and test functions\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    return train_loss\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # compute output\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    test_loss /= len(test_loader)\n",
    "    return test_loss\n",
    "\n",
    "# Use CUDA\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(2020) \n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed_all(2020)\n",
    "\n",
    "# load files\n",
    "moga = pickle.load(open(\"da.1208.pkl\", \"rb\"))\n",
    "x_train, x_test = moga[\"x_train\"], moga[\"x_test\"]\n",
    "y_train, y_test = moga[\"y_train\"], moga[\"y_test\"]\n",
    "x_mean, x_std = moga[\"x_mean\"], moga[\"x_std\"]\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test.reshape(-1,1)).float()\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 128,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 4}\n",
    "\n",
    "# dataloader\n",
    "train_data = MOGADataset(x_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_data, **params)\n",
    "\n",
    "test_data = MOGADataset(x_test, y_test)\n",
    "test_loader = DataLoader(dataset=test_data, **params)\n",
    "\n",
    "model = MOGANet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8)\n",
    "\n",
    "# Training here\n",
    "for t in range(500):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion) \n",
    "    test_loss = test(model, device, test_loader, criterion)\n",
    "    if t%10 == 0:\n",
    "        print(t, train_loss, test_loss)\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "# save trained model\n",
    "torch.save(model.state_dict(), 'da.1208.pth')\n",
    "#model.load_state_dict(torch.load(\"da.1208.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-majority",
   "metadata": {},
   "source": [
    "#### 3. Model evaluation\n",
    "\n",
    "plot1.py and plot2.py visualize the training process. We can check if there's overfitting problem by checking those generated figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "plot1.py\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"da.out\", header=None, sep=' ')\n",
    "data = df.to_numpy()\n",
    "train = data[:, -2]\n",
    "test = data[:, -1]\n",
    "x = data[:, 0]\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.ylim(0, 2e+6) \n",
    "#plt.xlim(-0.027, -0.010) \n",
    "plt.plot(x, train, color='b', marker=\".\", alpha=0.75, label='training')  \n",
    "plt.plot(x, test, color='red', marker=\".\", alpha=0.75, label='test')  \n",
    "plt.title('DA')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.tick_params(axis='both', direction='out', grid_color='gray', grid_alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('da.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-township",
   "metadata": {},
   "source": [
    "<img src=\"da.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "plot2.py\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"ma.out\", header=None, sep=' ')\n",
    "data = df.to_numpy()\n",
    "train = data[:, -2]\n",
    "test = data[:, -1]\n",
    "x = data[:, 0]\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.ylim(0, 1.5e-06) \n",
    "#plt.xlim(-0.027, -0.010) \n",
    "plt.plot(x, train, color='b', marker=\".\", alpha=0.75, label='training')  \n",
    "plt.plot(x, test, color='red', marker=\".\", alpha=0.75, label='test')   \n",
    "plt.title('MA')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.tick_params(axis='both', direction='out', grid_color='gray', grid_alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('ma.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-binding",
   "metadata": {},
   "source": [
    "<img src=\"ma.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-projector",
   "metadata": {},
   "source": [
    "We can also plot the prediction results on test data using the following scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "plot3.py\n",
    "'''\n",
    "# load libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# definition of a simple fc model\n",
    "class MOGANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MOGANet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(11, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MOGADataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    \n",
    "# Use CUDA\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(2020) \n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed_all(2020)\n",
    "\n",
    "# load files\n",
    "moga = pickle.load(open(\"da.1208.pkl\", \"rb\"))\n",
    "x_train, x_test = moga[\"x_train\"], moga[\"x_test\"]\n",
    "y_train, y_test = moga[\"y_train\"], moga[\"y_test\"]\n",
    "x_mean, x_std = moga[\"x_mean\"], moga[\"x_std\"]\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test.reshape(-1,1)).float()\n",
    "\n",
    "model = MOGANet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8)\n",
    "\n",
    "model.load_state_dict(torch.load(\"da.1208.pth\"))\n",
    "\n",
    "model.eval()\n",
    "Yp = model(x_test)\n",
    "print(\"test MSE from criterion\")\n",
    "MSE = criterion(Yp, y_test).item()\n",
    "print(MSE)\n",
    "\n",
    "Yp = Yp[:,0].detach().numpy()\n",
    "y_test = y_test[:,0].detach().numpy()\n",
    "\n",
    "delta_y = Yp - y_test\n",
    "RMSE = np.sqrt(MSE)\n",
    "print(\"test RMSE of original data\")\n",
    "print(RMSE)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "num_bins = 2000\n",
    "plt.hist(delta_y, num_bins, facecolor='blue')\n",
    "plt.xlabel('DA Prediction Error')\n",
    "plt.xlim(-1000, 1000)\n",
    "plt.grid(True)\n",
    "#plt.title('RMSE: %.4f, N=%d' % (RMSE,len(x_test)))\n",
    "plt.title('RMSE: '+'{:.2e}'.format(RMSE)+', N=%d' % (len(x_test)))\n",
    "plt.tight_layout()\n",
    "plt.savefig('1.png')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "#plt.ylim(-0.0252, -0.011) \n",
    "#plt.xlim(-0.027, -0.010) \n",
    "plt.scatter(y_test, Yp, color='b', marker=\".\", alpha=0.75)  \n",
    "#plt.title('MOGA Input Variables')\n",
    "plt.xlabel('DA')\n",
    "plt.ylabel('Prediction')\n",
    "plt.tick_params(axis='both', direction='out', grid_color='gray', grid_alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-strengthening",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "<img src=\"2.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "plot4.py\n",
    "'''\n",
    "# load libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# definition of a simple fc model\n",
    "class MOGANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MOGANet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(11, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MOGADataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "# Use CUDA\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "random.seed(2020) \n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed_all(2020)\n",
    "\n",
    "# load files\n",
    "moga = pickle.load(open(\"ma.1208.pkl\", \"rb\"))\n",
    "x_train, x_test = moga[\"x_train\"], moga[\"x_test\"]\n",
    "y_train, y_test = moga[\"y_train\"], moga[\"y_test\"]\n",
    "x_mean, x_std = moga[\"x_mean\"], moga[\"x_std\"]\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test.reshape(-1,1)).float()\n",
    "\n",
    "model = MOGANet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8)\n",
    "\n",
    "model.load_state_dict(torch.load(\"ma.1208.pth\"))\n",
    "\n",
    "model.eval()\n",
    "Yp = model(x_test)\n",
    "print(\"test MSE from criterion\")\n",
    "MSE = criterion(Yp, y_test).item()\n",
    "print(MSE)\n",
    "\n",
    "Yp = Yp[:,0].detach().numpy()\n",
    "y_test = y_test[:,0].detach().numpy()\n",
    "\n",
    "delta_y = Yp - y_test\n",
    "RMSE = np.sqrt(MSE)\n",
    "print(\"test RMSE of original data\")\n",
    "print(RMSE)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "num_bins = 2000\n",
    "plt.hist(delta_y, num_bins, facecolor='blue')\n",
    "plt.xlabel('MA Prediction Error')\n",
    "plt.xlim(-0.0004,0.0004)\n",
    "plt.grid(True)\n",
    "#plt.title('RMSE: %.4f, N=%d' % (RMSE,len(x_test)))\n",
    "plt.title('RMSE: '+'{:.2e}'.format(RMSE)+', N=%d' % (len(x_test)))\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.png')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "#plt.ylim(-0.0252, -0.011) \n",
    "#plt.xlim(-0.027, -0.010) \n",
    "plt.scatter(y_test, Yp, color='b', marker=\".\", alpha=0.75)  \n",
    "#plt.title('MA ')\n",
    "plt.xlabel('MA')\n",
    "plt.ylabel('Prediction')\n",
    "plt.tick_params(axis='both', direction='out', grid_color='gray', grid_alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-source",
   "metadata": {},
   "source": [
    "<img src=\"4.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "<img src=\"5.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-relaxation",
   "metadata": {},
   "source": [
    "#### 4. Format conversion\n",
    "\n",
    "We need to convert two generated model files ending with .pth to .pt format. The new files da.1208.pt and ma.1208.pt will be inserted into MOGA code to start ML-MOGA run. We first need to provide the current mean and std of our training data to ts.da.py and ts.ma.py before the conversion.\n",
    "\n",
    "python ts.da.py <br />\n",
    "python ts.ma.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "Converting to Torch Script via Tracing\n",
    "Trained model for Dynamic Aperture\n",
    "ts.da.py\n",
    "'''\n",
    "\n",
    "# load libs\n",
    "import sys \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# definition of a simple fc model [2, 32, 64, 1]\n",
    "class MOGANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MOGANet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(11, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Use CUDA\n",
    "device = torch.device(\"cpu\")\n",
    "model = MOGANet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "model.load_state_dict(torch.load(\"da.1208.pth\"))\n",
    "model.eval()\n",
    "\n",
    "x_mean = np.array([14.028049, 9.7394512, 11.783254, 15.524115, 15.713844, 15.480341, -14.873348, -2.3504979, -7.1688257, -75.974958, -157.57141])\n",
    "x_std = np.array([3.80621681e-01, 5.89510194e-01, 9.37556664e-01, 2.50345962e-01, 2.14431638e-01, 3.52844788e-01, 3.24311876e-01, 1.64542081e-01, 2.05577563e-01, 2.79143321e+02, 3.02909397e+02])\n",
    "\n",
    "a = 13\n",
    "b = 9\n",
    "c = 12\n",
    "d = 15\n",
    "e = 15\n",
    "f = 15\n",
    "g = -14\n",
    "h = -2\n",
    "i = -7\n",
    "j = -13\n",
    "k = -31\n",
    "\n",
    "sample = np.array([a, b, c, d, e, f, g, h, i, j, k])\n",
    "sample = (sample - x_mean) / x_std\n",
    "x = torch.from_numpy(sample).float()\n",
    "\n",
    "traced_script_module = torch.jit.trace(model, x)\n",
    "traced_script_module.save(\"da.1208.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "Converting to Torch Script via Tracing\n",
    "Trained model for Momentum Aperture\n",
    "ts.ma.py\n",
    "'''\n",
    "\n",
    "# load libs\n",
    "import sys \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# definition of a simple fc model [2, 32, 64, 1]\n",
    "class MOGANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MOGANet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(11, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Use CUDA\n",
    "device = torch.device(\"cpu\")\n",
    "model = MOGANet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "model.load_state_dict(torch.load(\"ma.1208.pth\"))\n",
    "model.eval()\n",
    "\n",
    "x_mean = np.array([14.028049, 9.7394512, 11.783254, 15.524115, 15.713844, 15.480341, -14.873348, -2.3504979, -7.1688257, -75.974958, -157.57141])\n",
    "x_std = np.array([3.80621681e-01, 5.89510194e-01, 9.37556664e-01, 2.50345962e-01, 2.14431638e-01, 3.52844788e-01, 3.24311876e-01, 1.64542081e-01, 2.05577563e-01, 2.79143321e+02, 3.02909397e+02])\n",
    "\n",
    "a = 13\n",
    "b = 9\n",
    "c = 12\n",
    "d = 15\n",
    "e = 15\n",
    "f = 15\n",
    "g = -14\n",
    "h = -2\n",
    "i = -7\n",
    "j = -13\n",
    "k = -31\n",
    "\n",
    "sample = np.array([a, b, c, d, e, f, g, h, i, j, k])\n",
    "sample = (sample - x_mean) / x_std\n",
    "x = torch.from_numpy(sample).float()\n",
    "\n",
    "traced_script_module = torch.jit.trace(model, x)\n",
    "traced_script_module.save(\"ma.1208.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "'''\n",
    "Script to calculate the mean and std for ts.da.py, ts.ma.py and problem.cpp\n",
    "'''\n",
    "\n",
    "# load libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# load files\n",
    "path = './dat/'\n",
    "fs = os.listdir(path)\n",
    "data = []\n",
    "\n",
    "# read files\n",
    "for f in fs:\n",
    "    tmp_df = pd.read_csv(path+f, header=None)\n",
    "    data.append(tmp_df)\n",
    "df = pd.concat(data, ignore_index=True, sort =False)\n",
    "\n",
    "# get X and Y\n",
    "data = df.to_numpy()\n",
    "x = data[:, -3]\n",
    "data = data[x == 0]\n",
    "X = data[:,20:31]\n",
    "Y_t = data[:,15:17]\n",
    "Y = np.mean(Y_t, axis=1)\n",
    "\n",
    "# split data into training set and test set\n",
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(X, Y, test_size=0.20, random_state=2020)\n",
    "\n",
    "# data normalization to [0, 1]\n",
    "x_mean = np.mean(x_train_o, axis=0)\n",
    "x_std = np.std(x_train_o, axis=0)\n",
    "print(x_mean)\n",
    "print(x_std)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "s1 = \"x_mean = np.array([\"\n",
    "s2 = \"x_std = np.array([\"\n",
    "\n",
    "for i in x_mean:\n",
    "    s1 += \"{:.8}\".format(i) + \", \"\n",
    "s1 = s1[:-2]\n",
    "\n",
    "for i in x_std:\n",
    "    s2 += \"{:.8e}\".format(i) + \", \"\n",
    "s2 = s2[:-2]\n",
    "\n",
    "s1 += \"])\"\n",
    "s2 += \"])\"\n",
    "\n",
    "print(s1)\n",
    "print(s2)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "pool = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\", \"gg\", \"hh\", \"ii\", \"jj\", \"kk\"]\n",
    "nums = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for idx in range(len(x_mean)):\n",
    "    print(\"    float \" + pool[idx] + \" = (xvar[\" + str(nums[idx]) + \"] - \" + \"{:.8}\".format(x_mean[idx]) + \") / \" + \"{:.8e}\".format(x_std[idx]) + \";\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-cowboy",
   "metadata": {},
   "source": [
    "#### 5. ML-MOGA run\n",
    "\n",
    "1) Copy the converted model files (da.1208.pt and ma.1208.pt) to ML_package.\n",
    "\n",
    "2) Copy libtorch library files to ML_package.\n",
    "\n",
    "3) Replace problem.cpp with PyTorch models. The ML version of problem.cpp is listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <math.h>\n",
    "#include <unistd.h>\n",
    "#include \"Tracy.Meso.h\"\n",
    "#include \"ALSU.h\"\n",
    "#include \"global.h\"\n",
    "#include <torch/script.h>\n",
    "#include <iostream>\n",
    "#include <stdexcept>\n",
    "#include <string>\n",
    "\n",
    "extern ALS_U_V17 *SR;\n",
    "\n",
    "string exec(string command) {\n",
    "   char buffer[128];\n",
    "   string result = \"\";\n",
    "\n",
    "   // Open pipe to file\n",
    "   FILE* pipe = popen(command.c_str(), \"r\");\n",
    "   if (!pipe) {\n",
    "      return \"popen failed!\";\n",
    "   }\n",
    "\n",
    "   // read till end of process:\n",
    "   while (!feof(pipe)) {\n",
    "\n",
    "      // use buffer to read and add to result\n",
    "      if (fgets(buffer, 128, pipe) != NULL)\n",
    "         result += buffer;\n",
    "   }\n",
    "\n",
    "   pclose(pipe);\n",
    "   return result;\n",
    "}\n",
    "\n",
    "double SegQ, SegB;\n",
    "ALS_U_V17 *Ring() {\n",
    "    SegQ = 1;\n",
    "    SegB = 3;\n",
    "    SR = new ALS_U_V17(SegQ,SegB);\n",
    "\n",
    "    SR->Individualize();\n",
    "    SR->SetIntegrator(4);\n",
    "    SR->SetSec6(10);\n",
    "\n",
    "    return SR;\n",
    "}\n",
    "\n",
    "void test_problem (int gen, int nload, double *xvar,  double *obj, double *constr,double *db) {\n",
    "    int i,j;\n",
    "    double maxBx=0,maxBy=0,maxEta=0;\n",
    "    double B3Betax = 0,B3Betay=0;\n",
    "    Belement *C;\n",
    "\n",
    "    SR->clearQuadGradErr();\n",
    "    SR->clearQuadSkew();\n",
    "    SR->ClearRef();\n",
    "    SR->ClearCOD();\n",
    "    SR->FixedPoint.clear();\n",
    "    SR->FixedPoint6.clear();\n",
    "    SR->ClearRef6();\n",
    "    SR->SetdP(0.0);\n",
    "    SR->Sextpoles_TurnOff();\n",
    "\n",
    "    double kqf1 =  xvar[0];\n",
    "    double kqf2 =  xvar[1];\n",
    "    double kqf3 =  xvar[2];\n",
    "    double kqf4 =  xvar[3];\n",
    "    double kqf5 =  xvar[4];\n",
    "    double kqf6 =  xvar[5];\n",
    "    double kqd1 =  xvar[6];\n",
    "    double kb1 =  xvar[7];\n",
    "    double kb2 =  xvar[8];\n",
    "    double kb3 =  xvar[8];\n",
    "    double kshh, kshh2; \n",
    "    // Input for training mdoel\n",
    "    kshh = xvar[9];\n",
    "    kshh2 = xvar[10];\n",
    "\n",
    "    ////////////////////////                                                                                                                                   \n",
    "    // linear lattice                                                                                                                                          \n",
    "    ////////////////////                                                                                                                                       \n",
    "\n",
    "    SR->setKQf1(kqf1);\n",
    "    SR->setKQf2(kqf2);\n",
    "    SR->setKQf3(kqf3);\n",
    "    SR->setKQf4(kqf4);\n",
    "    SR->setKQf5(kqf5);\n",
    "    SR->setKQf6(kqf6);\n",
    "    SR->setKQd1(kqd1);\n",
    "    SR->Quads[7]->SetK(kb1);\n",
    "    SR->Quads[8]->SetK(kb2);\n",
    "    SR->Quads[9]->SetK(kb3);\n",
    "\n",
    "#ifdef TESTRUN\n",
    "    SR->GetTwiss(1);\n",
    "#endif\n",
    "\n",
    "    if(!SR->GetTwiss(1))\n",
    "    {\n",
    "        for (i=0;i<ndb;i++)     db[i]=999.0;\n",
    "        for (i=0;i<ncon;i++)    constr[i]=-1.0;\n",
    "        for (i=0;i<nobj;i++)    obj[i] = 999.0+i*fabs(xvar[0]);\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    SR->CalcIntegral();\n",
    "    SR->CalcEmittance(2.0E9);\n",
    "    SR->SetA44();\n",
    "  \n",
    "#ifdef TESTRUN\n",
    "\n",
    "    SR->GetTwiss(1);\n",
    "    SR->CalcIntegral();\n",
    "    SR->ListSynch(stdout);\n",
    "    SR->listTwissTable(\"Twiss.txt\");\n",
    "\n",
    "    C=&(SR->Belem[0]);\n",
    "    FILE *fid = fopen(\"magnet.txt\",\"w\");\n",
    "    for(int n=0; n< SR->NoB;n++) {\n",
    "        C = &(SR->Belem[n]);\n",
    "        fprintf(fid,\" %d   %s  %d   %d  \\n\", n, C->Elem->Name.c_str(), C->Elem->GetSec6(), C->Elem->IntegMethod );\n",
    "\n",
    "    }\n",
    "    fclose(fid);\n",
    "#endif\n",
    "\n",
    "    C=&(SR->Belem[0]);\n",
    "\n",
    "    db[0] = C->TwissH.v[1]; //betax at s=0;                                                                                                                  \n",
    "    db[1] = C->TwissV.v[1]; //betay at s = 0;                                                                                                                \n",
    "    db[10] = C->Eta.v[0];   //etax at s= 0;                                                                                                                  \n",
    "\n",
    "    int inj_sn,qf1_sn,qf2_sn,qf3_sn,qf4_sn,qf5_sn,qf6_sn;\n",
    "\n",
    "    for(int n=0; n< SR->NoB;n++) {\n",
    "        C = &(SR->Belem[n]);\n",
    "        if (C->TwissH.v[1]>maxBx) maxBx = C->TwissH.v[1];\n",
    "        if (C->TwissV.v[1]>maxBy) maxBy = C->TwissV.v[1];\n",
    "        if (C->Eta.v[0]>maxEta) maxEta = C->Eta.v[0];\n",
    "\n",
    "        if (strncmp(\"B3M\",C->Elem->Name.c_str(),3)==0) {\n",
    "            B3Betax = C->TwissH.v[1];\n",
    "            B3Betay = C->TwissV.v[1];\n",
    "        }\n",
    "\n",
    "        if(strncmp(\"SECT1\",C->Elem->Name.c_str(),5)==0) inj_sn = 0;\n",
    "        if(strncmp(\"QF1(01)\",C->Elem->Name.c_str(),7)==0) qf1_sn = n;\n",
    "        if(strncmp(\"QF2(01)\",C->Elem->Name.c_str(),7)==0) qf2_sn = n;\n",
    "        if(strncmp(\"QF6(01)\",C->Elem->Name.c_str(),7)==0) qf6_sn = n;\n",
    "    }                                                                                                \n",
    "\n",
    "    db[2] = SR->NtlEmittance;  //emittance                                                                                                    \n",
    "    db[3] = SR->A44.m[0][0]+SR->A44.m[1][1]; //tracex                                                                                                          \n",
    "    db[4] = SR->A44.m[2][2]+SR->A44.m[3][3]; //tracey                                                                                                          \n",
    "    db[5] = SR->Jx;  //jx                                                                                                                       \n",
    "    db[6] = SR->Jz;  //jy                                                                                                                     \n",
    "    db[7] = SR->Je;  //j                                                                                                                                      \n",
    "    db[8] = SR->TuneH;   //tunex                                                                                                                                 \n",
    "    db[9] = SR->TuneV;   //tuney     \n",
    "    db[11] = SR->ChromH;\n",
    "    db[12] = SR->ChromV;\n",
    "    db[13] = B3Betax;\n",
    "    db[14] = B3Betay;\n",
    "\n",
    "    constr[0] = 2-fabs(db[3]);\n",
    "    constr[1] = 2-fabs(db[4]);\n",
    "    constr[2] = db[5];\n",
    "    constr[3] = db[6];\n",
    "    constr[4] = db[7];\n",
    "    constr[5] = 30-maxBx;  // maximum betax <25 m                                                                                                                \n",
    "    constr[6] = 30-maxBy; // maximum betay <25 m                                                                                                                 \n",
    "    constr[7] = 0.15-maxEta; // maximum etax <15 cm                                                                                                              \n",
    "    constr[8] = (155e-12-db[2]);  // emit <150 pm-rad \n",
    "\n",
    "    double ftunex = fabs(db[8]-(int) db[8]);\n",
    "    double ftuney = fabs(db[9]-(int) db[9]);\n",
    "\n",
    "    constr[9] = (ftunex-0.1)*(0.4-ftunex);\n",
    "    constr[10] = (ftuney-0.1)*(0.4-ftuney);\n",
    "    constr[11] = 1e-3-fabs(db[10]); //etax <1mm at s = 0;                                                                                                        \n",
    "    constr[12] = (db[0]-1)*(5-db[0]); //1<betax<5\n",
    "    constr[13] = (db[1]-1)*(5-db[1]); //1<betay<5\n",
    "    constr[14] = (4-B3Betax)*(4-B3Betay);\n",
    "    constr[15] = 0.01-fabs(ftunex-ftuney);\n",
    "\n",
    "    /* normialize the constraints*/\n",
    "    for (i=0;i<16;i++) {\n",
    "        if (constr[i]<0||isnan(constr[i])) {\n",
    "#ifdef TESTRUN\n",
    "            printf(\" ----- constr vio %d, %f\\n\",i,constr[i]);\n",
    "#endif \n",
    "            constr[i]=-1;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    obj[0]=db[2];\n",
    "    constr[16] = 0.0;\n",
    "    constr[17] = 0.0;\n",
    "\n",
    "    //////////////////////////                                                                                                                          \n",
    "    // nonliear optimziation                                                                                                                                   \n",
    "    //////////////////////////   \n",
    "\n",
    "    SR->Sexts[2]->SetK(kshh);\n",
    "    SR->Sexts[3]->SetK(kshh2);\n",
    "\n",
    "    if (!SR->FitChrom(1.0,1.0)) {\n",
    "        db[15]=0.0;\n",
    "        db[16]=0.0;\n",
    "        db[17]= 0.0;\n",
    "\n",
    "        db[18]=0.0;\n",
    "        db[19]= 0.0;\n",
    "        constr[16] = -1.0;\n",
    "        constr[17] = -1.0;\n",
    "        obj[1]=9999.0;\n",
    "\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    db[18] = SR->GetSF();\n",
    "    db[19] = SR->GetSD();\n",
    "\n",
    "    constr[16] = 900-fabs(db[18]);\n",
    "    constr[17] = 900-fabs(db[19]);  \n",
    "\n",
    "    srand(199);\n",
    "    SR->setQuadSkew(5e-4);\n",
    "    SR->setQuadGradErr(2e-4);\n",
    "  \n",
    "#ifdef TESTRUN\n",
    "    printf(\" ---SF: %32.28f, SD:%32.28f\\n\",SR->GetSF(),SR->GetSD());\n",
    "    SR->GetTwiss(1);\n",
    "    SR->CalcIntegral();\n",
    "    SR->ListSynch(stdout);\n",
    "    SR->listTwissTable(\"Twiss_1.txt\");\n",
    "    SR->Tracy2AT(\"lattice.m\");\n",
    "#endif\n",
    "  \n",
    "    //double MomAper1[2],MomAper2[2],MomAper3[2],MomAper4[2];\n",
    "\n",
    "#ifdef TESTRUN\n",
    "    \n",
    "#else\n",
    "    // Input\n",
    "    float aa = (xvar[0] - 14.028049) / 3.80621681e-01;\n",
    "    float bb = (xvar[1] - 9.7394512) / 5.89510194e-01;\n",
    "    float cc = (xvar[2] - 11.783254) / 9.37556664e-01;\n",
    "    float dd = (xvar[3] - 15.524115) / 2.50345962e-01;\n",
    "    float ee = (xvar[4] - 15.713844) / 2.14431638e-01;\n",
    "    float ff = (xvar[5] - 15.480341) / 3.52844788e-01;\n",
    "    float gg = (xvar[6] - -14.873348) / 3.24311876e-01;\n",
    "    float hh = (xvar[7] - -2.3504979) / 1.64542081e-01;\n",
    "    float ii = (xvar[8] - -7.1688257) / 2.05577563e-01;\n",
    "    float jj = (xvar[9] - -75.974958) / 2.79143321e+02;\n",
    "    float kk = (xvar[10] - -157.57141) / 3.02909397e+02;\n",
    "\n",
    "    auto X = torch::tensor({aa, bb, cc, dd, ee, ff, gg, hh, ii, jj, kk}, torch::requires_grad(false).dtype(torch::kFloat32)).view({1,11});\n",
    "    vector<torch::jit::IValue> inputs;\n",
    "    inputs.push_back(X);\n",
    "\n",
    "    // da\n",
    "    torch::jit::script::Module module_da = torch::jit::load(\"da.1208.pt\");\n",
    "\n",
    "    // Execute the model and turn its output into a tensor.\n",
    "    at::Tensor output_da = module_da.forward(inputs).toTensor();\n",
    "    db[15] = output_da.item<float>();\n",
    "    db[16] = output_da.item<float>();\n",
    "    \n",
    "    // ma\n",
    "    torch::jit::script::Module module_ma = torch::jit::load(\"ma.1208.pt\");\n",
    "    \n",
    "    // Execute the model and turn its output into a tensor.\n",
    "    at::Tensor output_ma = module_ma.forward(inputs).toTensor();\n",
    "    db[17] = output_ma.item<float>();\n",
    "#endif\n",
    "\n",
    "    obj[1]=(db[15]+db[16])/2;\n",
    "    obj[2]=db[17];\n",
    "\n",
    "    if (isnan(obj[1])) obj[1]=9999.0;\n",
    "    if (isnan(obj[2])) obj[2]=9999.0; \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-delicious",
   "metadata": {},
   "source": [
    "4) Remember to replace float aa - kk with the current mean and std, same as format conversion.\n",
    "\n",
    "5) Other minor changes please refer to NERSC/ml-run/7_moga/ML_package.\n",
    "\n",
    "6) Create build directory and run the following command to compile executable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir build\n",
    "\n",
    "cd build\n",
    "\n",
    "cmake -DCMAKE_CXX_COMPILER=mpiCC -DCMAKE_C_COMPILER=mpicc -DCMAKE_PREFIX_PATH=./libtorch ..\n",
    "\n",
    "make\n",
    "\n",
    "mv nsga2r .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-transcription",
   "metadata": {},
   "source": [
    "7) Submit the job script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch scanjob.s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-tyler",
   "metadata": {},
   "source": [
    "#### 6. Tracking validation and distance metric\n",
    "\n",
    "After the ML-MOGA run, we pick a specific generation file as input to do one tracking validation run. We use two distance metrics as standards to pick that genration. ds1.py and ds2.py will plot the distance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# ds1.py for input variables\n",
    "# load libs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def extract(fname):\n",
    "   dm = np.genfromtxt(fname, delimiter=',', usecols=range(20,31)) / magnet_range\n",
    "   return dm\n",
    "\n",
    "magnet_range = np.array((2.8, 3, 4.97, 2.54, 3.29, 2.82, 2.56, 1.29, 1.24, 1160, 1160))\n",
    "\n",
    "def ds1(df1, df2):\n",
    "   dist = 0\n",
    "   for idx in range(0, 5000, 1):\n",
    "     dist += np.sum(np.linalg.norm((df1[idx,:] - df2[:,:]),axis=1))   #Most of the slowdown was in this loop.\n",
    "   dist /= (5000*4999)\n",
    "   return dist\n",
    "\n",
    "a = []\n",
    "x1 = list(range(1, 1376, 1))\n",
    "\n",
    "# 1204 114\n",
    "x = extract('/data/ylu/11knobs/res/ml/7_ml/gen_1_db.dat')\n",
    "for idx in range(1, 1376, 1):\n",
    "    y = extract('/data/ylu/11knobs/res/ml/7_ml/gen_'+str(idx+1)+'_db.dat')\n",
    "    res = ds1(x, y)\n",
    "    a.append(res)\n",
    "    x = y\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x1, a, color='r', marker=\".\", alpha=0.75, label='ml moga')\n",
    "plt.xlabel('generation')\n",
    "plt.ylabel('distance')\n",
    "plt.tick_params(axis='both', direction='out', grid_color='gray', grid_alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('ods1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-title",
   "metadata": {},
   "source": [
    "An example output of ds1.py\n",
    "\n",
    "<img src=\"ods1.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# ds2.py for output solutions\n",
    "# load libs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def extract(fname):\n",
    "    df = pd.read_csv(fname, header=None)\n",
    "    data = df.to_numpy()\n",
    "    da_t = data[:,15:17]\n",
    "    da = np.mean(da_t, axis=1).reshape(-1, 1)\n",
    "    ma = data[:,17].reshape(-1, 1)\n",
    "    em = data[:,2].reshape(-1, 1)\n",
    "    dm = np.hstack((da, ma, em))\n",
    "    return dm\n",
    "\n",
    "def ds3(df):\n",
    "    eps0 = 90\n",
    "    da0 = -60000\n",
    "    ma0 = -0.03\n",
    "    delta = 0\n",
    "\n",
    "    for idx in range(0, 5000, 1):\n",
    "      delta += ((df[idx, 2] - eps0) / eps0) ** 2 + ((df[idx, 0] - da0) / da0) ** 2 + ((df[idx, 1] - ma0) / ma0) ** 2\n",
    "\n",
    "    delta = math.sqrt(delta) / 5000\n",
    "    return delta\n",
    "\n",
    "a = []\n",
    "x1 = list(range(1, 1377, 1))\n",
    "\n",
    "# 1204 114\n",
    "for idx in range(1, 1377, 1):\n",
    "    y = extract('/data/ylu/11knobs/res/ml/7_ml/gen_'+str(idx)+'_db.dat')\n",
    "    res = ds3(y)\n",
    "    a.append(res)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "#plt.ylim(-0.029, -0.026) \n",
    "plt.scatter(x1, a, color='r', marker=\".\", alpha=0.75, label='ml moga')\n",
    "#plt.title('(max-min) / overall_range')\n",
    "plt.xlabel('generation')\n",
    "plt.ylabel('distance')\n",
    "plt.tick_params(axis='both', direction='out', grid_color='gray', grid_alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('ods3.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-bahamas",
   "metadata": {},
   "source": [
    "An example output of ds2.py\n",
    "\n",
    "<img src=\"ods3.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-degree",
   "metadata": {},
   "source": [
    "#### 7. Results visualization\n",
    "\n",
    "Below are some examples to visualize the results for better comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# input variables comparison\n",
    "# load libs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract(fname):\n",
    "    df = pd.read_csv(fname, header=None)\n",
    "    data = df.to_numpy()\n",
    "    a = data[:,20]\n",
    "    b = data[:,21]\n",
    "    c = data[:,22]\n",
    "    d = data[:,23]\n",
    "    e = data[:,24]\n",
    "    f = data[:,25]\n",
    "    g = data[:,26]\n",
    "    h = data[:,27]\n",
    "    i = data[:,28]\n",
    "    j = data[:,29]\n",
    "    k = data[:,30]\n",
    "    return a, b, c, d, e, f, g, h, i, j, k\n",
    "\n",
    "a1, b1, c1, d1, e1, f1, g1, h1, i1, j1, k1 = extract('/data/ylu/11knobs/res/rand/rand_9/gen_63_db.dat')\n",
    "a5, b5, c5, d5, e5, f5, g5, h5, i5, j5, k5 = extract('/data/ylu/11knobs/res/rd_ml/rd_5_ml/gen_900_db.dat')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(a1, alpha=0.5, color='blue', label=\"Tr-MOGA\")\n",
    "plt.hist(a5, alpha=0.5, color='yellow', label=\"ML-MOGA\")\n",
    "plt.ylabel(\"Count\", size=14)\n",
    "plt.title(\"var 1\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"exm.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-marathon",
   "metadata": {},
   "source": [
    "<img src=\"exm.jpg\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# output solutions comparison\n",
    "# load libs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/data/ylu/11knobs/res/ori/0111_moga/gen_94_db.dat', header=None)\n",
    "data = df.to_numpy()\n",
    "da_t = data[:,15:17]\n",
    "da = np.mean(da_t, axis=1)\n",
    "ma = data[:,17]\n",
    "\n",
    "df1 = pd.read_csv('/data/ylu/11knobs/res/rand/rand_9/gen_63_db.dat', header=None)\n",
    "data1 = df1.to_numpy()\n",
    "da_t1 = data1[:,15:17]\n",
    "da1 = np.mean(da_t1, axis=1)\n",
    "ma1 = data1[:,17]\n",
    "\n",
    "df0 = pd.read_csv('/data/ylu/11knobs/res/track/7.1_track/gen_1_db.dat', header=None)\n",
    "data0 = df0.to_numpy()\n",
    "data3 = data0[data0[:,-2] == 1]\n",
    "da_t0 = data3[:,15:17]\n",
    "da0 = np.mean(da_t0, axis=1)\n",
    "ma0 = data3[:,17]\n",
    "\n",
    "df4 = pd.read_csv('/data/ylu/11knobs/res/rd_track/rd_5.1_track/gen_1_db.dat', header=None)\n",
    "data4 = df4.to_numpy()\n",
    "data5 = data4[data4[:,-2] == 1]\n",
    "da_t4 = data5[:,15:17]\n",
    "da4 = np.mean(da_t4, axis=1)\n",
    "ma4 = data5[:,17]\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(abs(da), abs(ma)*100, color='b', marker=\".\", alpha=0.75, label='Blue: Tr-MOGA 1') \n",
    "plt.scatter(abs(da1), abs(ma1)*100, color='grey', marker=\".\", alpha=0.75, label='Gray: Tr-MOGA 2')\n",
    "plt.scatter(abs(da0), abs(ma0)*100, color='black', marker=\".\", alpha=0.75, label='Black: ML-MOGA 1')\n",
    "plt.scatter(abs(da4), abs(ma4)*100, color='yellow', marker=\".\", alpha=0.75, label='Yellow: ML-MOGA 2')\n",
    "plt.title('MOGA Output Parameters')\n",
    "plt.xlabel('Dynamic Aperture [a.u]')\n",
    "plt.ylabel('Momentum Aperture [%]')\n",
    "plt.tick_params(axis='both', direction='out', grid_color='gray', grid_alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('sol.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-mortality",
   "metadata": {},
   "source": [
    "<img src=\"sol.jpg\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# ml vs corresponding tracking rank 1 (difference of distance metric for output solutions)\n",
    "# load libs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def extract(fname):\n",
    "    df = pd.read_csv(fname, header=None)\n",
    "    data = df.to_numpy()\n",
    "    da_t = data[:,15:17]\n",
    "    da = np.mean(da_t, axis=1).reshape(-1, 1)\n",
    "    ma = data[:,17].reshape(-1, 1)\n",
    "    em = data[:,2].reshape(-1, 1)\n",
    "    dm = np.hstack((da, ma, em))\n",
    "    return dm\n",
    "\n",
    "def extract1(fname):\n",
    "    df = pd.read_csv(fname, header=None)\n",
    "    data1 = df.to_numpy()\n",
    "    data = data1[data1[:,-2] == 1]\n",
    "    da_t = data[:,15:17]\n",
    "    da = np.mean(da_t, axis=1).reshape(-1, 1)\n",
    "    ma = data[:,17].reshape(-1, 1)\n",
    "    em = data[:,2].reshape(-1, 1)\n",
    "    dm = np.hstack((da, ma, em))\n",
    "    return dm\n",
    "\n",
    "def ds3(df):\n",
    "    l = len(df)\n",
    "    eps0 = 90\n",
    "    da0 = -60000\n",
    "    ma0 = -0.03\n",
    "    delta = 0\n",
    "\n",
    "    for idx in range(0, l, 1):\n",
    "      delta += ((df[idx, 2] - eps0) / eps0) ** 2 + ((df[idx, 0] - da0) / da0) ** 2 + ((df[idx, 1] - ma0) / ma0) ** 2\n",
    "\n",
    "    delta = math.sqrt(delta) / l\n",
    "    return delta\n",
    "\n",
    "a = []\n",
    "x = list(range(1, 8, 1))\n",
    "\n",
    "x1 = ds3(extract('/data/ylu/11knobs/res/ml/1.1_ml/gen_732_db.dat'))\n",
    "x2 = ds3(extract1('/data/ylu/11knobs/res/track/1.1_track/gen_1_db.dat'))\n",
    "print(\"{:.4f}\".format(x1))\n",
    "print(\"{:.4f}\".format(x2))\n",
    "print(\"\\n\")\n",
    "a.append(x1 - x2)\n",
    "\n",
    "x1 = ds3(extract('/data/ylu/11knobs/res/ml/2.1_ml/gen_900_db.dat'))\n",
    "x2 = ds3(extract1('/data/ylu/11knobs/res/track/2.1_track/gen_1_db.dat'))\n",
    "print(\"{:.4f}\".format(x1))\n",
    "print(\"{:.4f}\".format(x2))\n",
    "print(\"\\n\")\n",
    "a.append(x1 - x2)\n",
    "\n",
    "x1 = ds3(extract('/data/ylu/11knobs/res/ml/3.1_ml/gen_600_db.dat'))\n",
    "x2 = ds3(extract1('/data/ylu/11knobs/res/track/3.1_track/gen_1_db.dat'))\n",
    "print(\"{:.4f}\".format(x1))\n",
    "print(\"{:.4f}\".format(x2))\n",
    "print(\"\\n\")\n",
    "a.append(x1 - x2)\n",
    "\n",
    "x1 = ds3(extract('/data/ylu/11knobs/res/ml/4_ml/gen_1200_db.dat'))\n",
    "x2 = ds3(extract1('/data/ylu/11knobs/res/track/4.1_track/gen_1_db.dat'))\n",
    "print(\"{:.4f}\".format(x1))\n",
    "print(\"{:.4f}\".format(x2))\n",
    "print(\"\\n\")\n",
    "a.append(x1 - x2)\n",
    "\n",
    "x1 = ds3(extract('/data/ylu/11knobs/res/ml/5_ml/gen_900_db.dat'))\n",
    "x2 = ds3(extract1('/data/ylu/11knobs/res/track/5.1_track/gen_1_db.dat'))\n",
    "print(\"{:.4f}\".format(x1))\n",
    "print(\"{:.4f}\".format(x2))\n",
    "print(\"\\n\")\n",
    "a.append(x1 - x2)\n",
    "\n",
    "x1 = ds3(extract('/data/ylu/11knobs/res/ml/6_ml/gen_400_db.dat'))\n",
    "x2 = ds3(extract1('/data/ylu/11knobs/res/track/6.1_track/gen_1_db.dat'))\n",
    "print(\"{:.4f}\".format(x1))\n",
    "print(\"{:.4f}\".format(x2))\n",
    "print(\"\\n\")\n",
    "a.append(x1 - x2)\n",
    "\n",
    "x1 = ds3(extract('/data/ylu/11knobs/res/ml/7_ml/gen_700_db.dat'))\n",
    "x2 = ds3(extract1('/data/ylu/11knobs/res/track/7.1_track/gen_1_db.dat'))\n",
    "print(\"{:.4f}\".format(x1))\n",
    "print(\"{:.4f}\".format(x2))\n",
    "print(\"\\n\")\n",
    "a.append(x1 - x2)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x, a, color='r', marker=\".\", alpha=0.75, label='x.0 vs x.1 rank 1')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('diff of ds3')\n",
    "plt.tick_params(axis='both', direction='out', grid_color='gray', grid_alpha=0.5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('exm1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-maple",
   "metadata": {},
   "source": [
    "<img src=\"exm1.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
